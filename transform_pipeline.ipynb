{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad3bd1b-9550-4280-a4dc-cf661d2d79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf6e4a8-2911-44ce-9c48-c0c92f99d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "the_wizard = os.getenv(\"WIZARD\")\n",
    "the_spell = os.getenv(\"LEVIOSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab628338-8f65-4529-8bc7-45bc0be91d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_performance(start_time, end_time, image_count, log_csv='performance_log.csv'):\n",
    "    duration = end_time - start_time\n",
    "    log_data = {\n",
    "        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'image_count': image_count,\n",
    "        'duration_seconds': round(duration, 2)\n",
    "    }\n",
    "\n",
    "    file_exists = os.path.isfile(log_csv)\n",
    "    with open(log_csv, 'a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=log_data.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d77eff-ec90-45ee-a156-ab7080761930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(csv_path):\n",
    "    return pd.read_csv(csv_path)['image_path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718f980d-ab98-4255-8190-2fd654b32ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_paths(processed_csv):\n",
    "    if os.path.exists(processed_csv):\n",
    "        return set(pd.read_csv(processed_csv)['path'].tolist())\n",
    "    return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5724a6-1425-416b-b1b2-8cb73bcc391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_paths(processed_csv, new_paths):\n",
    "    df = pd.DataFrame({'path': list(new_paths)})\n",
    "    if os.path.exists(processed_csv):\n",
    "        existing = pd.read_csv(processed_csv)\n",
    "        df = pd.concat([existing, df], ignore_index=True).drop_duplicates()\n",
    "    df.to_csv(processed_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db113b12-b505-4560-8526-fa0bef03d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_images(image_paths, wizard, spell, content_response):\n",
    "    for path in image_paths:\n",
    "        parts = os.path.basename(path).split('_')\n",
    "        statistic = '_'.join(parts[:-1])\n",
    "        country = parts[-1].replace('.png', '')\n",
    "\n",
    "        response = chat(\n",
    "            model=wizard,\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': spell,\n",
    "                    'images': [path],\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        if country not in content_response:\n",
    "            content_response[country] = {}\n",
    "        content_response[country][statistic] = response.message.content\n",
    "    print(content_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83228cf8-8c47-49c8-a8a7-6a7d6feccc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ollama_response(text):\n",
    "    # Step 1: Remove all asterisks\n",
    "    text = text.replace('*', '')\n",
    "    \n",
    "    # Step 2: Remove all newline characters\n",
    "    text = text.replace('\\n', '')\n",
    "    \n",
    "    # Step 3: Remove everything before and including the first colon\n",
    "    colon_index = text.find(':')\n",
    "    if colon_index != -1:\n",
    "        text = text[colon_index + 1:]\n",
    "    \n",
    "    # Optional: Strip leading/trailing whitespace\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f51b53c-0f39-409c-a1cb-61f134c44203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_statistic_dataframes(data):\n",
    "    \"\"\"\n",
    "    Builds a dictionary of DataFrames, one per statistic.\n",
    "    Each DataFrame has years as index and countries as columns.\n",
    "    Missing values are filled with NaN.\n",
    "    \"\"\"\n",
    "    stats_data = defaultdict(lambda: defaultdict(dict))  # {stat: {year: {country: value}}}\n",
    "    all_countries = set(data.keys())  # Track all countries from input\n",
    "\n",
    "    for country, stats in data.items():\n",
    "        for stat_name, stat_text in stats.items():\n",
    "            cleaned = clean_ollama_response(stat_text)\n",
    "            matches = re.findall(r\"(\\d{4}):\\s*([\\d.]+)\", cleaned)\n",
    "            for year_str, value_str in matches:\n",
    "                try:\n",
    "                    year = int(year_str)\n",
    "                    value = float(value_str)\n",
    "                    stats_data[stat_name][year][country] = value\n",
    "                except ValueError:\n",
    "                    continue  # Skip malformed entries\n",
    "\n",
    "    stat_dfs = {}\n",
    "    for stat_name, year_country_values in stats_data.items():\n",
    "        df = pd.DataFrame.from_dict(year_country_values, orient='index').sort_index()\n",
    "        df = df.reindex(columns=all_countries)  # Ensure all countries are present\n",
    "        stat_dfs[stat_name] = df\n",
    "\n",
    "    return stat_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22008c8f-b051-432f-9823-c1c1dd328f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_statistic_dataframes_to_parquet(stat_dfs, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for name, new_df in stat_dfs.items():\n",
    "        output_path = os.path.join(output_dir, f\"{name}.parquet\")\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            existing_df = pd.read_parquet(output_path)\n",
    "\n",
    "            # Merge on index (years) and columns (countries)\n",
    "            combined_df = existing_df.combine_first(new_df)\n",
    "        else:\n",
    "            combined_df = new_df\n",
    "\n",
    "        combined_df.to_parquet(output_path, index=True)\n",
    "        print(f\"âœ… Merged: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94f2c89e-2898-4827-ba71-c54c30c814af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extraction_pipeline(\n",
    "    input_csv,\n",
    "    processed_csv,\n",
    "    model=the_wizard,\n",
    "    spell=the_spell,\n",
    "    batch_size=4,\n",
    "    output_dir='parquet_exports'\n",
    "):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Load paths\n",
    "    all_paths = load_image_paths(input_csv)\n",
    "    processed_paths = load_processed_paths(processed_csv)\n",
    "    remaining_paths = [p for p in all_paths if p not in processed_paths]\n",
    "\n",
    "    # Step 2: Select batch\n",
    "    batch_paths = remaining_paths[:batch_size]\n",
    "    print(f\"Processing {len(batch_paths)} images...\")\n",
    "\n",
    "    # Step 3: Extract data\n",
    "    content_response = {}\n",
    "    extract_data_from_images(batch_paths, model, spell, content_response)\n",
    "\n",
    "    # Step 4: Save processed paths\n",
    "    save_processed_paths(processed_csv, batch_paths)\n",
    "\n",
    "    # Step 5: Build DataFrames and export\n",
    "    stat_dfs = build_statistic_dataframes(content_response)\n",
    "    export_statistic_dataframes_to_parquet(stat_dfs, output_dir=output_dir)\n",
    "\n",
    "    end_time = time.time()\n",
    "    log_performance(start_time, end_time, len(batch_paths))\n",
    "    print(f\"The process for {len(batch_paths)} images has finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb2d3223-7f5b-4088-b78f-156553469a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 images...\n",
      "{'Austria': {'labor_force': 'Claro, aquÃ­ tienes los datos extraÃ­dos de la imagen:\\n\\n*   **2016:** 4.57\\n*   **2017:** 4.60\\n*   **2018:** 4.64\\n*   **2019:** 4.66\\n*   **2020:** 4.64\\n*   **2021:** 4.69\\n*   **2022:** 4.76\\n*   **2023:** 4.83', 'livestock_production_index': 'AquÃ­ estÃ¡n los aÃ±os y valores extraÃ­dos del grÃ¡fico:\\n\\n*   **2015:** 101.2\\n*   **2016:** 101.4\\n*   **2017:** 101.4\\n*   **2018:** 101.5\\n*   **2019:** 101.1\\n*   **2020:** 100.9\\n*   **2021:** 100.3\\n*   **2022:** 100.4', 'Percent_agricultural_land': 'AquÃ­ estÃ¡n los aÃ±os y valores extraÃ­dos de la imagen:\\n\\n*   **2015:** 32.94\\n*   **2016:** 32.36\\n*   **2017:** 32.17\\n*   **2018:** 32.15\\n*   **2019:** 32.13\\n*   **2020:** 31.54\\n*   **2021:** 31.54\\n*   **2022:** 31.48', 'Percent_urban_population': 'Claro, aquÃ­ estÃ¡n los aÃ±os y valores del grÃ¡fico que proporcionaste:\\n\\n*   2016: 57.90\\n*   2017: 58.09\\n*   2018: 58.30\\n*   2019: 58.51\\n*   2020: 58.75\\n*   2021: 58.99\\n*   2022: 59.26\\n*   2023: 59.53'}}\n",
      "âœ… Merged: parquet_exports\\labor_force.parquet\n",
      "âœ… Merged: parquet_exports\\livestock_production_index.parquet\n",
      "âœ… Merged: parquet_exports\\Percent_agricultural_land.parquet\n",
      "âœ… Merged: parquet_exports\\Percent_urban_population.parquet\n",
      "The process for 4 images has finished.\n"
     ]
    }
   ],
   "source": [
    "run_extraction_pipeline(\n",
    "    input_csv='data/image_paths.csv',\n",
    "    processed_csv='data/processed_paths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "300e11df-4bf3-4df2-a8aa-e1fe60d670e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet_files(directory):\n",
    "    dataframes = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".parquet\"):\n",
    "            path = os.path.join(directory, filename)\n",
    "            df = pd.read_parquet(path)\n",
    "            dataframes[filename] = df\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fedb898-61f8-416b-8b0a-82159ea4d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ File: labor_force.parquet\n",
      "      Australia\n",
      "2016      12.73\n",
      "2017      13.01\n",
      "2018      13.31\n",
      "2019      13.59\n",
      "2020      13.58\n",
      "\n",
      "ðŸ“„ File: livestock_production_index.parquet\n",
      "      Australia\n",
      "2015      102.4\n",
      "2016       96.8\n",
      "2017       91.0\n",
      "2018       97.2\n",
      "2019       97.7\n",
      "\n",
      "ðŸ“„ File: Percent_agricultural_land.parquet\n",
      "      Australia\n",
      "2015      45.31\n",
      "2016      44.54\n",
      "2017      48.34\n",
      "2018      46.66\n",
      "2019      47.12\n",
      "\n",
      "ðŸ“„ File: Percent_urban_population.parquet\n",
      "      Australia\n",
      "2016      85.80\n",
      "2017      85.90\n",
      "2018      86.01\n",
      "2019      86.12\n",
      "2020      86.24\n"
     ]
    }
   ],
   "source": [
    "# Load all Parquet files from the output directory\n",
    "parquet_data = load_parquet_files(\"parquet_exports\")\n",
    "\n",
    "# Inspect each DataFrame\n",
    "for name, df in parquet_data.items():\n",
    "    print(f\"\\nðŸ“„ File: {name}\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6ee9b0b-7741-43e2-8c68-073f061d96fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ File: labor_force.parquet\n",
      "      Australia  Austria\n",
      "2016      12.73     4.57\n",
      "2017      13.01     4.60\n",
      "2018      13.31     4.64\n",
      "2019      13.59     4.66\n",
      "2020      13.58     4.64\n",
      "\n",
      "ðŸ“„ File: livestock_production_index.parquet\n",
      "      Australia  Austria\n",
      "2015      102.4    101.2\n",
      "2016       96.8    101.4\n",
      "2017       91.0    101.4\n",
      "2018       97.2    101.5\n",
      "2019       97.7    101.1\n",
      "\n",
      "ðŸ“„ File: Percent_agricultural_land.parquet\n",
      "      Australia  Austria\n",
      "2015      45.31    32.94\n",
      "2016      44.54    32.36\n",
      "2017      48.34    32.17\n",
      "2018      46.66    32.15\n",
      "2019      47.12    32.13\n",
      "\n",
      "ðŸ“„ File: Percent_urban_population.parquet\n",
      "      Australia  Austria\n",
      "2016      85.80    57.90\n",
      "2017      85.90    58.09\n",
      "2018      86.01    58.30\n",
      "2019      86.12    58.51\n",
      "2020      86.24    58.75\n"
     ]
    }
   ],
   "source": [
    "# Load all Parquet files from the output directory\n",
    "parquet_data = load_parquet_files(\"parquet_exports\")\n",
    "\n",
    "# Inspect each DataFrame\n",
    "for name, df in parquet_data.items():\n",
    "    print(f\"\\nðŸ“„ File: {name}\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c712fc-97ae-4ad1-aceb-ef045c62db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_extraction_pipeline(\n",
    "    input_csv='data/image_paths.csv',\n",
    "    processed_csv='data/processed_paths.csv',\n",
    "    batch_size=16\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
